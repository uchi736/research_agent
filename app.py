import streamlit as st
import uuid
from research_agent import get_agent_runnable, FollowUpQuestions

# Streamlitãƒšãƒ¼ã‚¸ã®åŸºæœ¬è¨­å®š
st.set_page_config(page_title="Deep Research Agent", layout="wide")
st.title("ğŸ§  Deep Research Agent")
st.markdown("`LangChain` ã¨ `LangGraph` ã‚’åˆ©ç”¨ã—ãŸæ·±æ˜ã‚Šèª¿æŸ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒè‡ªå¾‹çš„ã«èª¿æŸ»è¨ˆç”»ã‚’ç«‹ã¦ã€Webæ¤œç´¢ã‚’è¡Œã„ã€æœ€çµ‚çš„ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† ---
if "agent" not in st.session_state:
    st.session_state.agent = get_agent_runnable()
if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())
if "step" not in st.session_state:
    st.session_state.step = "start"
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ ---
def display_messages():
    """ã“ã‚Œã¾ã§ã®ã‚„ã‚Šå–ã‚Šã‚’è¡¨ç¤ºã™ã‚‹"""
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

def reset_conversation():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆã—ã¦æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™"""
    st.session_state.clear()
    st.session_state.step = "start"
    st.session_state.messages = []


# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
st.sidebar.title("è¨­å®š")
st.sidebar.button("æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™", on_click=reset_conversation)
st.sidebar.markdown("---")
st.sidebar.subheader("LangSmith ãƒˆãƒ¬ãƒ¼ã‚¹")
st.sidebar.markdown(
    """
    [LangSmith](https://smith.langchain.com/) ã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ä½œã‚’è©³ç´°ã«è¿½è·¡ã™ã‚‹ã«ã¯ã€`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã®è¨­å®šã‚’è¿½åŠ ã—ã¦ãã ã•ã„:
    ```
    LANGCHAIN_TRACING_V2="true"
    LANGCHAIN_API_KEY="YOUR_LANGSMITH_API_KEY"
    LANGCHAIN_PROJECT="Deep Research Agent"
    ```
    è¨­å®šå¾Œã€ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚
    """
)


# --- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

# 1. åˆæœŸã‚¯ã‚¨ãƒªã®å…¥åŠ›ã‚¹ãƒ†ãƒƒãƒ—
if st.session_state.step == "start":
    st.info("èª¿æŸ»ã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯ã‚„è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    initial_query = st.text_input("èª¿æŸ»ãƒˆãƒ”ãƒƒã‚¯:", key="initial_query_input")
    
    if initial_query:
        st.session_state.messages.append({"role": "user", "content": initial_query})
        
        with st.spinner("ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒèª¿æŸ»è¨ˆç”»ã‚’ç«‹ã¦ã€è³ªå•ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."):
            config = {"configurable": {"thread_id": st.session_state.thread_id}}
            inputs = {"initial_query": initial_query}
            
            for event in st.session_state.agent.stream(inputs, config, stream_mode="values"):
                if "follow_up_for_user" in event:
                    st.session_state.follow_up_questions = event["follow_up_for_user"].questions
                    st.session_state.research_plan = event["research_plan"]
                    st.session_state.step = "answer_follow_ups"
                    st.rerun()

# 2. ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—è³ªå•ã¸ã®å›ç­”ã‚¹ãƒ†ãƒƒãƒ—
elif st.session_state.step == "answer_follow_ups":
    display_messages()
    
    with st.chat_message("assistant"):
        st.markdown("èª¿æŸ»ã®ç²¾åº¦ã‚’é«˜ã‚ã‚‹ãŸã‚ã€ã„ãã¤ã‹è³ªå•ã•ã›ã¦ãã ã•ã„ã€‚")
        st.info(f"**èª¿æŸ»è¨ˆç”»:** åºƒã• `({st.session_state.research_plan.breadth})`, æ·±ã• `({st.session_state.research_plan.depth})`\n\n**ç†ç”±:** {st.session_state.research_plan.explanation}")
        
        with st.form("follow_up_form"):
            answers = []
            for i, q in enumerate(st.session_state.follow_up_questions):
                answers.append({"question": q, "answer": st.text_input(q, key=f"answer_{i}")})
            
            if st.form_submit_button("å›ç­”ã‚’é€ä¿¡ã—ã¦èª¿æŸ»ã‚’é–‹å§‹"):
                initial_query = st.session_state.messages[0]['content']
                answers_text = "\n".join([f"Q: {a['question']}\nA: {a['answer']}" for a in answers if a['answer']])
                st.session_state.combined_query = f"åˆæœŸã‚¯ã‚¨ãƒª: {initial_query}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹è£œè¶³:\n{answers_text}"
                
                st.session_state.messages.append({"role": "user", "content": f"ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã¸ã®å›ç­”:\n```\n{answers_text}\n```"})
                st.session_state.step = "researching"
                st.rerun()

# 3. èª¿æŸ»å®Ÿè¡Œã‚¹ãƒ†ãƒƒãƒ—
elif st.session_state.step == "researching":
    display_messages()
    
    with st.chat_message("assistant"):
        st.markdown("ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ãŸã ã„ã¾ã‹ã‚‰æ·±æ˜ã‚Šèª¿æŸ»ã‚’é–‹å§‹ã—ã¾ã™ã€‚")

        with st.spinner("AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒèª¿æŸ»ã‚’å®Ÿè¡Œä¸­ã§ã™..."):
            progress_area = st.empty()
            
            config = {"configurable": {"thread_id": st.session_state.thread_id}}
            inputs = {"combined_query": st.session_state.combined_query}

            final_report = None
            for event in st.session_state.agent.stream(inputs, config, stream_mode="values"):
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«é€²æ—ã‚’è¡¨ç¤º
                if "generate_initial_queries" in event:
                    progress_area.info("æœ€åˆã®æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
                elif "execute_search" in event:
                    current_state = event["execute_search"]
                    progress_area.info(f"**éšå±¤ {current_state.get('current_depth', 1)} ã®èª¿æŸ»ä¸­...**\n\næ¬¡ã®ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¾ã™:\n- " + "\n- ".join(current_state.get('queries_to_run', [])))
                elif "generate_report" in event:
                    progress_area.info("ã™ã¹ã¦ã®èª¿æŸ»ãŒå®Œäº†ã—ã¾ã—ãŸã€‚æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ã„ã¾ã™...")

                if "final_report" in event:
                    final_report = event["final_report"]

            if final_report:
                st.session_state.messages.append({"role": "assistant", "content": final_report})
                st.session_state.step = "done"
                st.rerun()

# 4. å®Œäº†ã‚¹ãƒ†ãƒƒãƒ—
elif st.session_state.step == "done":
    display_messages()
    st.success("èª¿æŸ»ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

# æœ€åˆã®è¡¨ç¤º
if st.session_state.step == "start":
    display_messages()
